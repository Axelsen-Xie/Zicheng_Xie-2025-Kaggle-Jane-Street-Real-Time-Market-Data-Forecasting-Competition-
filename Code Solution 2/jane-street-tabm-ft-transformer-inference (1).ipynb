{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42c31bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:03.629799Z",
     "iopub.status.busy": "2024-12-18T15:35:03.629076Z",
     "iopub.status.idle": "2024-12-18T15:35:12.820806Z",
     "shell.execute_reply": "2024-12-18T15:35:12.818551Z"
    },
    "papermill": {
     "duration": 9.200666,
     "end_time": "2024-12-18T15:35:12.823827",
     "exception": false,
     "start_time": "2024-12-18T15:35:03.623161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rtdl_num_embeddings -q --no-index --find-links=/kaggle/input/jane-street-import/rtdl_num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1e3fe0",
   "metadata": {
    "_cell_guid": "8936e699-b090-4d2b-9bf2-b77f90fbefdb",
    "_uuid": "f573766f-0a4b-4a41-a873-d3e78e56afaf",
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:12.831869Z",
     "iopub.status.busy": "2024-12-18T15:35:12.831102Z",
     "iopub.status.idle": "2024-12-18T15:35:21.099941Z",
     "shell.execute_reply": "2024-12-18T15:35:21.099190Z"
    },
    "papermill": {
     "duration": 8.274866,
     "end_time": "2024-12-18T15:35:21.102017",
     "exception": false,
     "start_time": "2024-12-18T15:35:12.827151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "from tanm_reference import Model, make_parameter_groups\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "from pytorch_lightning import LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51586c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:21.108777Z",
     "iopub.status.busy": "2024-12-18T15:35:21.108094Z",
     "iopub.status.idle": "2024-12-18T15:35:21.122911Z",
     "shell.execute_reply": "2024-12-18T15:35:21.122289Z"
    },
    "papermill": {
     "duration": 0.019596,
     "end_time": "2024-12-18T15:35:21.124398",
     "exception": false,
     "start_time": "2024-12-18T15:35:21.104802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\n",
    "\n",
    "target_col = \"responder_6\" \n",
    "\n",
    "feature_test = feature_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_test if item not in feature_cat]\n",
    "\n",
    "batch_size = 8192\n",
    "\n",
    "std_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c00e392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:21.130919Z",
     "iopub.status.busy": "2024-12-18T15:35:21.130168Z",
     "iopub.status.idle": "2024-12-18T15:35:21.140499Z",
     "shell.execute_reply": "2024-12-18T15:35:21.139621Z"
    },
    "papermill": {
     "duration": 0.015199,
     "end_time": "2024-12-18T15:35:21.142184",
     "exception": false,
     "start_time": "2024-12-18T15:35:21.126985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n",
    " 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n",
    " 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n",
    "  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n",
    " 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n",
    "  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n",
    " 'time_id' : {i : i for i in range(968)}}\n",
    "\n",
    "def encode_column(df, column, mapping):\n",
    "    max_value = max(mapping.values())  \n",
    "\n",
    "    def encode_category(category):\n",
    "        return mapping.get(category, max_value + 1)  \n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column).map_elements(encode_category).alias(column)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9f3c9",
   "metadata": {
    "papermill": {
     "duration": 0.002184,
     "end_time": "2024-12-18T15:35:21.146888",
     "exception": false,
     "start_time": "2024-12-18T15:35:21.144704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TabM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74d3a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:21.152844Z",
     "iopub.status.busy": "2024-12-18T15:35:21.152577Z",
     "iopub.status.idle": "2024-12-18T15:35:21.960193Z",
     "shell.execute_reply": "2024-12-18T15:35:21.959505Z"
    },
    "papermill": {
     "duration": 0.812926,
     "end_time": "2024-12-18T15:35:21.962135",
     "exception": false,
     "start_time": "2024-12-18T15:35:21.149209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = torch.sum((y_pred - y_true) ** 2)\n",
    "        var_y = torch.sum(y_true ** 2)\n",
    "        loss = mse_loss / (var_y + 1e-38)\n",
    "        return loss\n",
    "\n",
    "class NN(LightningModule):\n",
    "    def __init__(self, n_cont_features, cat_cardinalities, n_classes, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.k = 16\n",
    "        self.model = Model(\n",
    "                n_num_features=n_cont_features,\n",
    "                cat_cardinalities=cat_cardinalities,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    'type': 'MLP',\n",
    "                    'n_blocks': 3 ,\n",
    "                    'd_block': 512,\n",
    "                    'dropout': 0.25,\n",
    "                },\n",
    "                bins=None,\n",
    "                num_embeddings= None,\n",
    "                arch_type='tabm',\n",
    "                k=self.k,\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.loss_fn = R2Loss()\n",
    "        # self.loss_fn = weighted_mse_loss\n",
    "\n",
    "    def forward(self, x_cont, x_cat):\n",
    "        return self.model(x_cont, x_cat).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x_cont,x_cat, y, w , w_y= batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.training_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x_cont,x_cat, y, w, w_y = batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.validation_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n",
    "        #                                                        verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            # 'lr_scheduler': {\n",
    "            #     'scheduler': scheduler,\n",
    "            #     'monitor': 'val_r_square',\n",
    "            # }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "\n",
    "        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n",
    "        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        # r2_training\n",
    "        train_r_square = r2_val(y, prob, weights)\n",
    "        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "        \n",
    "class custom_args():\n",
    "    def __init__(self):\n",
    "        self.usegpu = True\n",
    "        self.gpuid = 0\n",
    "        self.seed = 42\n",
    "        self.model = 'nn'\n",
    "        self.use_wandb = False\n",
    "        self.project = 'js-tabm-with-lags'\n",
    "        self.dname = \"./input_df/\"\n",
    "        self.loader_workers = 10   \n",
    "        self.bs = 8192\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 8e-4\n",
    "        self.n_cont_features = 84\n",
    "        self.n_cat_features = 5\n",
    "        self.n_classes = None\n",
    "        self.cat_cardinalities = [23, 10, 32, 40, 969]\n",
    "        self.patience = 7\n",
    "        self.max_epochs = 10\n",
    "        self.N_fold = 5\n",
    "\n",
    "\n",
    "my_args = custom_args()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NN.load_from_checkpoint('/kaggle/input/my-own-js/tabm_epochepoch03.ckpt').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4336b5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:21.969523Z",
     "iopub.status.busy": "2024-12-18T15:35:21.969207Z",
     "iopub.status.idle": "2024-12-18T15:35:21.980841Z",
     "shell.execute_reply": "2024-12-18T15:35:21.980055Z"
    },
    "papermill": {
     "duration": 0.017617,
     "end_time": "2024-12-18T15:35:21.982418",
     "exception": false,
     "start_time": "2024-12-18T15:35:21.964801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "lags_history = None\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_, lags_history\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "    \n",
    "    for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "        test = encode_column(test, col, category_mappings[col])\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    \n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "\n",
    "    time_id = test.select(\"time_id\").to_numpy()[0]\n",
    "    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n",
    "    \n",
    "    \n",
    "    if time_id == 0:\n",
    "        lags = lags.with_columns(pl.col('time_id').cast(pl.Int64))\n",
    "        lags = lags.with_columns(pl.col('symbol_id').cast(pl.Int64))\n",
    "    \n",
    "        lags_history = lags\n",
    "        lags = lags.filter(pl.col(\"time_id\") == 0)\n",
    "        \n",
    "        \n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        lags = lags_history.filter(pl.col(\"time_id\") == time_id)\n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "\n",
    "    \n",
    "    test = test.with_columns([\n",
    "        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "    ])\n",
    "\n",
    "    test = standardize(test, std_feature, means, stds)\n",
    "\n",
    "\n",
    "    X_test = test[feature_test].to_numpy()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n",
    "    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n",
    "    X_cat = X_test_tensor[:, [9, 10, 11]]\n",
    "    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n",
    "    # X_cont = X_cont + torch.randn_like(X_cont) * 0.02\n",
    "\n",
    "    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs = model(X_cont, X_cat)\n",
    "        # Assuming the model outputs a tensor of shape (batch_size, 1)\n",
    "        preds = outputs.squeeze(-1).cpu().numpy()\n",
    "        preds = preds.mean(1)\n",
    "    \n",
    "    \n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    # The predict function must return a DataFrame\n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    # with columns 'row_id', 'responer_6'\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    # and as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60875118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:21.988326Z",
     "iopub.status.busy": "2024-12-18T15:35:21.988075Z",
     "iopub.status.idle": "2024-12-18T15:35:22.586970Z",
     "shell.execute_reply": "2024-12-18T15:35:22.585954Z"
    },
    "papermill": {
     "duration": 0.60392,
     "end_time": "2024-12-18T15:35:22.588811",
     "exception": false,
     "start_time": "2024-12-18T15:35:21.984891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 138 ms, total: 242 ms\n",
      "Wall time: 593 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EVAL = False\n",
    "if EVAL:\n",
    "    test_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet'\n",
    "    lags_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet'\n",
    "else:\n",
    "    test_dir = '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet'\n",
    "    lags_dir = '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet'\n",
    "\n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            test_dir,\n",
    "            lags_dir\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c18174b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:22.595097Z",
     "iopub.status.busy": "2024-12-18T15:35:22.594824Z",
     "iopub.status.idle": "2024-12-18T15:35:22.599159Z",
     "shell.execute_reply": "2024-12-18T15:35:22.598477Z"
    },
    "papermill": {
     "duration": 0.009161,
     "end_time": "2024-12-18T15:35:22.600707",
     "exception": false,
     "start_time": "2024-12-18T15:35:22.591546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_zero_mean_r2(y_true, y_pred, weights):\n",
    "    \"\"\"\n",
    "    Calculate the sample weighted zero-mean R-squared score.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy.ndarray): Ground-truth values for responder_6.\n",
    "    y_pred (numpy.ndarray): Predicted values for responder_6.\n",
    "    weights (numpy.ndarray): Sample weight vector.\n",
    "\n",
    "    Returns:\n",
    "    float: The weighted zero-mean R-squared score.\n",
    "    \"\"\"\n",
    "    numerator = np.sum(weights * (y_true - y_pred)**2)\n",
    "    denominator = np.sum(weights * y_true**2)\n",
    "    \n",
    "    r2_score = 1 - numerator / denominator\n",
    "    return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d7acb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:22.606744Z",
     "iopub.status.busy": "2024-12-18T15:35:22.606444Z",
     "iopub.status.idle": "2024-12-18T15:35:22.610933Z",
     "shell.execute_reply": "2024-12-18T15:35:22.610113Z"
    },
    "papermill": {
     "duration": 0.009228,
     "end_time": "2024-12-18T15:35:22.612487",
     "exception": false,
     "start_time": "2024-12-18T15:35:22.603259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "\n",
    "    submission_file = pd.read_parquet('/kaggle/working/submission.parquet')\n",
    "    y_pred = submission_file['responder_6']\n",
    "    \n",
    "    valid_df = pl.read_parquet(\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/valid_df.parquet\")\n",
    "    \n",
    "    y_true = valid_df.select(\"responder_6\").to_numpy().reshape(-1)\n",
    "    \n",
    "    weights = valid_df.select(\"weight\").to_numpy().reshape(-1)\n",
    "    \n",
    "    print(weighted_zero_mean_r2(y_true, y_pred, weights))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6297065,
     "sourceId": 10235634,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 204479873,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 207787842,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 212973694,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 213144305,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.598855,
   "end_time": "2024-12-18T15:35:24.890362",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T15:35:01.291507",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
